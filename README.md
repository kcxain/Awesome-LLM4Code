# Awesome-LLM4Code



## 2025-07 

## 0710-0717

- [GitChameleon: Evaluating AI Code Generation Against Python Library Version Incompatibilities](archive/2025-07/0717.md#GitChameleon-Evaluating-AI-Code-Generation-Against-Python-Library-Version-Incompatibilities)
- [Chain-of-Descriptions: Improving Code LLMs for VHDL Code Generation and Summarization](archive/2025-07/0717.md#Chain-of-Descriptions-Improving-Code-LLMs-for-VHDL-Code-Generation-and-Summarization)
- [MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks](archive/2025-07/0717.md#MERA-Code-A-Unified-Framework-for-Evaluating-Code-Generation-Across-Tasks)
- [ExpliCIT-QA: Explainable Code-Based Image Table Question Answering](archive/2025-07/0717.md#ExpliCIT-QA-Explainable-Code-Based-Image-Table-Question-Answering)
- [MetaLint: Generalizable Idiomatic Code Quality Analysis through Instruction-Following and Easy-to-Hard Generalization](archive/2025-07/0717.md#MetaLint-Generalizable-Idiomatic-Code-Quality-Analysis-through-Instruction-Following-and-Easy-to-Hard-Generalization)
- [The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs](archive/2025-07/0717.md#The-Devil-behind-the-mask-An-emergent-safety-vulnerability-of-Diffusion-LLMs)
- [Function-to-Style Guidance of LLMs for Code Translation](archive/2025-07/0717.md#Function-to-Style-Guidance-of-LLMs-for-Code-Translation)
- [CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks](archive/2025-07/0717.md#CodeJudgeBench-Benchmarking-LLM-as-a-Judge-for-Coding-Tasks)
- [CodeAssistBench (CAB): Dataset & Benchmarking for Multi-turn Chat-Based Code Assistance](archive/2025-07/0717.md#CodeAssistBench-CAB-Dataset--Benchmarking-for-Multi-turn-Chat-Based-Code-Assistance)
- [A Code Comprehension Benchmark for Large Language Models for Code](archive/2025-07/0717.md#A-Code-Comprehension-Benchmark-for-Large-Language-Models-for-Code)
- [Turning the Tide: Repository-based Code Reflection](archive/2025-07/0717.md#Turning-the-Tide-Repository-based-Code-Reflection)
- [A Mixture of Linear Corrections Generates Secure Code](archive/2025-07/0717.md#A-Mixture-of-Linear-Corrections-Generates-Secure-Code)
- [OpenCodeReasoning-II: A Simple Test Time Scaling Approach via Self-Critique](archive/2025-07/0717.md#OpenCodeReasoning-II-A-Simple-Test-Time-Scaling-Approach-via-Self-Critique)
- [On Evaluating Performance of LLM Inference Serving Systems](archive/2025-07/0717.md#On-Evaluating-Performance-of-LLM-Inference-Serving-Systems)
- [BlockFFN: Towards End-Side Acceleration-Friendly Mixture-of-Experts with Chunk-Level Activation Sparsity](archive/2025-07/0717.md#BlockFFN-Towards-End-Side-Acceleration-Friendly-Mixture-of-Experts-with-Chunk-Level-Activation-Sparsity)
- [Multilingual Multimodal Software Developer for Code Generation](archive/2025-07/0717.md#Multilingual-Multimodal-Software-Developer-for-Code-Generation)
- [Agentic Large Language Models for Conceptual Systems Engineering and Design](archive/2025-07/0717.md#Agentic-Large-Language-Models-for-Conceptual-Systems-Engineering-and-Design)
- [Automating MD simulations for Proteins using Large language Models: NAMD-Agent](archive/2025-07/0717.md#Automating-MD-simulations-for-Proteins-using-Large-language-Models-NAMD-Agent)

### 0703-0710

- [Rethinking Verification for LLM Code Generation: From Generation to Testing](archive/2025-07/0710.md#Rethinking-Verification-for-LLM-Code-Generation-From-Generation-to-Testing)
- [Text to model via SysML: Automated generation of dynamical system computational models from unstructured natural language text via enhanced System Modeling Language diagrams](archive/2025-07/0710.md#Text-to-model-via-SysML-Automated-generation-of-dynamical-system-computational-models-from-unstructured-natural-language-text-via-enhanced-System-Modeling-Language-diagrams)
- [Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models](archive/2025-07/0710.md#Foundation-Model-Self-Play-Open-Ended-Strategy-Innovation-via-Foundation-Models)
- [A Semantic Parsing Framework for End-to-End Time Normalization](archive/2025-07/0710.md#A-Semantic-Parsing-Framework-for-End-to-End-Time-Normalization)
- [Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving](archive/2025-07/0710.md#Agent-KB-Leveraging-Cross-Domain-Experience-for-Agentic-Problem-Solving)
- [Coding Triangle: How Does Large Language Model Understand Code?](archive/2025-07/0710.md#Coding-Triangle-How-Does-Large-Language-Model-Understand-Code)
- [CogniSQL-R1-Zero: Lightweight Reinforced Reasoning for Efficient SQL Generation](archive/2025-07/0710.md#CogniSQL-R1-Zero-Lightweight-Reinforced-Reasoning-for-Efficient-SQL-Generation)
- [Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning](archive/2025-07/0710.md#Learn-Globally-Speak-Locally-Bridging-the-Gaps-in-Multilingual-Reasoning)
- [ArtifactsBench: Bridging the Visual-Interactive Gap in LLM Code Generation Evaluation](archive/2025-07/0710.md#ArtifactsBench-Bridging-the-Visual-Interactive-Gap-in-LLM-Code-Generation-Evaluation)
- [ChipSeek-R1: Generating Human-Surpassing RTL with LLM via Hierarchical Reward-Driven Reinforcement Learning](archive/2025-07/0710.md#ChipSeek-R1-Generating-Human-Surpassing-RTL-with-LLM-via-Hierarchical-Reward-Driven-Reinforcement-Learning)
- [A Technical Survey of Reinforcement Learning Techniques for Large Language Models](archive/2025-07/0710.md#A-Technical-Survey-of-Reinforcement-Learning-Techniques-for-Large-Language-Models)
- [Is It Time To Treat Prompts As Code? A Multi-Use Case Study For Prompt Optimization Using DSPy](archive/2025-07/0710.md#Is-It-Time-To-Treat-Prompts-As-Code-A-Multi-Use-Case-Study-For-Prompt-Optimization-Using-DSPy)
- [EvoAgentX: An Automated Framework for Evolving Agentic Workflows](archive/2025-07/0710.md#EvoAgentX-An-Automated-Framework-for-Evolving-Agentic-Workflows)
- [CoreCodeBench: A Configurable Multi-Scenario Repository-Level Benchmark](archive/2025-07/0710.md#CoreCodeBench-A-Configurable-Multi-Scenario-Repository-Level-Benchmark)
- [Discovering Algorithms with Computational Language Processing](archive/2025-07/0710.md#Discovering-Algorithms-with-Computational-Language-Processing)
- [LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users](archive/2025-07/0710.md#LLM-Hypnosis-Exploiting-User-Feedback-for-Unauthorized-Knowledge-Injection-to-All-Users)
- [OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding](archive/2025-07/0710.md#OmniDraft-A-Cross-vocabulary-Online-Adaptive-Drafter-for-On-device-Speculative-Decoding)
- [FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference](archive/2025-07/0710.md#FlowSpec-Continuous-Pipelined-Speculative-Decoding-for-Efficient-Distributed-LLM-Inference)
- [Efficient Code LLM Training via Distribution-Consistent and Diversity-Aware Data Selection](archive/2025-07/0710.md#Efficient-Code-LLM-Training-via-Distribution-Consistent-and-Diversity-Aware-Data-Selection)
- [CORE: Benchmarking LLMs Code Reasoning Capabilities through Static Analysis Tasks](archive/2025-07/0710.md#CORE-Benchmarking-LLMs-Code-Reasoning-Capabilities-through-Static-Analysis-Tasks)

### 0626-0703

- [The Anatomy of Evidence: An Investigation Into Explainable ICD Coding](archive/2025-07/0703.md#The-Anatomy-of-Evidence-An-Investigation-Into-Explainable-ICD-Coding)
- [LogitSpec: Accelerating Retrieval-based Speculative Decoding via Next Next Token Speculation](archive/2025-07/0703.md#LogitSpec-Accelerating-Retrieval-based-Speculative-Decoding-via-Next-Next-Token-Speculation)
- [LLM-based Realistic Safety-Critical Driving Video Generation](archive/2025-07/0703.md#LLM-based-Realistic-Safety-Critical-Driving-Video-Generation)
- [Echoes of AI: Investigating the Downstream Effects of AI Assistants on Software Maintainability](archive/2025-07/0703.md#Echoes-of-AI-Investigating-the-Downstream-Effects-of-AI-Assistants-on-Software-Maintainability)
- [Cognitive Load-Aware Inference: A Neuro-Symbolic Framework for Optimizing the Token Economy of Large Language Models](archive/2025-07/0703.md#Cognitive-Load-Aware-Inference-A-Neuro-Symbolic-Framework-for-Optimizing-the-Token-Economy-of-Large-Language-Models)
- [iPanda: An Intelligent Protocol Testing and Debugging Agent for Conformance Testing](archive/2025-07/0703.md#iPanda-An-Intelligent-Protocol-Testing-and-Debugging-Agent-for-Conformance-Testing)
- [An AST-guided LLM Approach for SVRF Code Synthesis](archive/2025-07/0703.md#An-AST-guided-LLM-Approach-for-SVRF-Code-Synthesis)
- [Teaching Programming in the Age of Generative AI: Insights from Literature, Pedagogical Proposals, and Student Perspectives](archive/2025-07/0703.md#Teaching-Programming-in-the-Age-of-Generative-AI-Insights-from-Literature-Pedagogical-Proposals-and-Student-Perspectives)
- [VoyagerVision: Investigating the Role of Multi-modal Information for Open-ended Learning Systems](archive/2025-07/0703.md#VoyagerVision-Investigating-the-Role-of-Multi-modal-Information-for-Open-ended-Learning-Systems)
- [Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation](archive/2025-07/0703.md#Smaller--Weaker-Benchmarking-Robustness-of-Quantized-LLMs-in-Code-Generation)
- [Beyond Code: The Multidimensional Impacts of Large Language Models in Software Development](archive/2025-07/0703.md#Beyond-Code-The-Multidimensional-Impacts-of-Large-Language-Models-in-Software-Development)
- [P4OMP: Retrieval-Augmented Prompting for OpenMP Parallelism in Serial Code](archive/2025-07/0703.md#P4OMP-Retrieval-Augmented-Prompting-for-OpenMP-Parallelism-in-Serial-Code)
- [VOCABTRIM: Vocabulary Pruning for Efficient Speculative Decoding in LLMs](archive/2025-07/0703.md#VOCABTRIM-Vocabulary-Pruning-for-Efficient-Speculative-Decoding-in-LLMs)
- [QuickSilver -- Speeding up LLM Inference through Dynamic Token Halting, KV Skipping, Contextual Token Fusion, and Adaptive Matryoshka Quantization](archive/2025-07/0703.md#QuickSilver----Speeding-up-LLM-Inference-through-Dynamic-Token-Halting-KV-Skipping-Contextual-Token-Fusion-and-Adaptive-Matryoshka-Quantization)
- [Concept-Level AI for Telecom: Moving Beyond Large Language Models](archive/2025-07/0703.md#Concept-Level-AI-for-Telecom-Moving-Beyond-Large-Language-Models)
- [Exploring Modularity of Agentic Systems for Drug Discovery](archive/2025-07/0703.md#Exploring-Modularity-of-Agentic-Systems-for-Drug-Discovery)
- [Training Language Model to Critique for Better Refinement](archive/2025-07/0703.md#Training-Language-Model-to-Critique-for-Better-Refinement)
- [Estimating Correctness Without Oracles in LLM-Based Code Generation](archive/2025-07/0703.md#Estimating-Correctness-Without-Oracles-in-LLM-Based-Code-Generation)


## 2025-06 

### 0619-0626

- [DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation](archive/2025-06/0626.md#DiffuCoder-Understanding-and-Improving-Masked-Diffusion-Models-for-Code-Generation)
- [Large Language Model-Driven Code Compliance Checking in Building Information Modeling](archive/2025-06/0626.md#Large-Language-Model-Driven-Code-Compliance-Checking-in-Building-Information-Modeling)
- [ReCode: Updating Code API Knowledge with Reinforcement Learning](archive/2025-06/0626.md#ReCode-Updating-Code-API-Knowledge-with-Reinforcement-Learning)
- [SV-LLM: An Agentic Approach for SoC Security Verification using Large Language Models](archive/2025-06/0626.md#SV-LLM-An-Agentic-Approach-for-SoC-Security-Verification-using-Large-Language-Models)
- [Language Modeling by Language Models](archive/2025-06/0626.md#Language-Modeling-by-Language-Models)
- [Zero-Shot Attribution for Large Language Models: A Distribution Testing Approach](archive/2025-06/0626.md#Zero-Shot-Attribution-for-Large-Language-Models-A-Distribution-Testing-Approach)
- [SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization](archive/2025-06/0626.md#SACL-Understanding-and-Combating-Textual-Bias-in-Code-Retrieval-with-Semantic-Augmented-Reranking-and-Localization)
- [QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges](archive/2025-06/0626.md#QHackBench-Benchmarking-Large-Language-Models-for-Quantum-Code-Generation-Using-PennyLane-Hackathon-Challenges)
- [Scaling Speculative Decoding with Lookahead Reasoning](archive/2025-06/0626.md#Scaling-Speculative-Decoding-with-Lookahead-Reasoning)
- [Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study](archive/2025-06/0626.md#Why-Do-Open-Source-LLMs-Struggle-with-Data-Analysis-A-Systematic-Empirical-Study)
- [From Reproduction to Replication: Evaluating Research Agents with Progressive Code Masking](archive/2025-06/0626.md#From-Reproduction-to-Replication-Evaluating-Research-Agents-with-Progressive-Code-Masking)
- [Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs](archive/2025-06/0626.md#Skywork-SWE-Unveiling-Data-Scaling-Laws-for-Software-Engineering-in-LLMs)
- [Steering Conceptual Bias via Transformer Latent-Subspace Activation](archive/2025-06/0626.md#Steering-Conceptual-Bias-via-Transformer-Latent-Subspace-Activation)
- [LLMs on a Budget? Say HOLA](archive/2025-06/0626.md#LLMs-on-a-Budget-Say-HOLA)
- [The Debugging Decay Index: Rethinking Debugging Strategies for Code LLMs](archive/2025-06/0626.md#The-Debugging-Decay-Index-Rethinking-Debugging-Strategies-for-Code-LLMs)
- [Use Property-Based Testing to Bridge LLM Code Generation and Validation](archive/2025-06/0626.md#Use-Property-Based-Testing-to-Bridge-LLM-Code-Generation-and-Validation)
- [RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation](archive/2025-06/0626.md#RoboTwin-20-A-Scalable-Data-Generator-and-Benchmark-with-Strong-Domain-Randomization-for-Robust-Bimanual-Robotic-Manipulation)
- [Tower+: Bridging Generality and Translation Specialization in Multilingual LLMs](archive/2025-06/0626.md#Tower-Bridging-Generality-and-Translation-Specialization-in-Multilingual-LLMs)
- [TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs](archive/2025-06/0626.md#TeXpert-A-Multi-Level-Benchmark-for-Evaluating-LaTeX-Code-Generation-by-LLMs)
- [AI-Driven Tools in Modern Software Quality Assurance: An Assessment of Benefits, Challenges, and Future Directions](archive/2025-06/0626.md#AI-Driven-Tools-in-Modern-Software-Quality-Assurance-An-Assessment-of-Benefits-Challenges-and-Future-Directions)
- [LMR-BENCH: Evaluating LLM Agent's Ability on Reproducing Language Modeling Research](archive/2025-06/0626.md#LMR-BENCH-Evaluating-LLM-Agents-Ability-on-Reproducing-Language-Modeling-Research)

### 0612-0619

- [Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and Training Factors Shape LLM Alignment Quality](archive/2025-06/0619.md#Massive-Supervised-Fine-tuning-Experiments-Reveal-How-Data-Layer-and-Training-Factors-Shape-LLM-Alignment-Quality)
- [StreetLens: Enabling Human-Centered AI Agents for Neighborhood Assessment from Street View Imagery](archive/2025-06/0619.md#StreetLens-Enabling-Human-Centered-AI-Agents-for-Neighborhood-Assessment-from-Street-View-Imagery)
- [Guaranteed Guess: A Language Modeling Approach for CISC-to-RISC Transpilation with Testing Guarantees](archive/2025-06/0619.md#Guaranteed-Guess-A-Language-Modeling-Approach-for-CISC-to-RISC-Transpilation-with-Testing-Guarantees)
- [Sampling from Your Language Model One Byte at a Time](archive/2025-06/0619.md#Sampling-from-Your-Language-Model-One-Byte-at-a-Time)
- [How Does LLM Reasoning Work for Code? A Survey and a Call to Action](archive/2025-06/0619.md#How-Does-LLM-Reasoning-Work-for-Code-A-Survey-and-a-Call-to-Action)
- [LocationReasoner: Evaluating LLMs on Real-World Site Selection Reasoning](archive/2025-06/0619.md#LocationReasoner-Evaluating-LLMs-on-Real-World-Site-Selection-Reasoning)
- [A Technical Study into Small Reasoning Language Models](archive/2025-06/0619.md#A-Technical-Study-into-Small-Reasoning-Language-Models)
- [FrontendBench: A Benchmark for Evaluating LLMs on Front-End Development via Automatic Evaluation](archive/2025-06/0619.md#FrontendBench-A-Benchmark-for-Evaluating-LLMs-on-Front-End-Development-via-Automatic-Evaluation)
- [Structured Program Synthesis using LLMs: Results and Insights from the IPARC Challenge](archive/2025-06/0619.md#Structured-Program-Synthesis-using-LLMs-Results-and-Insights-from-the-IPARC-Challenge)
- [Humanity's Last Code Exam: Can Advanced LLMs Conquer Human's Hardest Code Competition?](archive/2025-06/0619.md#Humanitys-Last-Code-Exam-Can-Advanced-LLMs-Conquer-Humans-Hardest-Code-Competition)
- [QiMeng-Attention: SOTA Attention Operator is generated by SOTA Attention Algorithm](archive/2025-06/0619.md#QiMeng-Attention-SOTA-Attention-Operator-is-generated-by-SOTA-Attention-Algorithm)
- [PRO-V: An Efficient Program Generation Multi-Agent System for Automatic RTL Verification](archive/2025-06/0619.md#PRO-V-An-Efficient-Program-Generation-Multi-Agent-System-for-Automatic-RTL-Verification)
- [code_transformed: The Influence of Large Language Models on Code](archive/2025-06/0619.md#code_transformed-The-Influence-of-Large-Language-Models-on-Code)
- [Configurable Preference Tuning with Rubric-Guided Synthetic Data](archive/2025-06/0619.md#Configurable-Preference-Tuning-with-Rubric-Guided-Synthetic-Data)
- [Leveraging GPT-4 for Vulnerability-Witnessing Unit Test Generation](archive/2025-06/0619.md#Leveraging-GPT-4-for-Vulnerability-Witnessing-Unit-Test-Generation)
- [Agent-RLVR: Training Software Engineering Agents via Guidance and Environment Rewards](archive/2025-06/0619.md#Agent-RLVR-Training-Software-Engineering-Agents-via-Guidance-and-Environment-Rewards)
- [LLM-as-a-Judge for Reference-less Automatic Code Validation and Refinement for Natural Language to Bash in IT Automation](archive/2025-06/0619.md#LLM-as-a-Judge-for-Reference-less-Automatic-Code-Validation-and-Refinement-for-Natural-Language-to-Bash-in-IT-Automation)
- [AutoMind: Adaptive Knowledgeable Agent for Automated Data Science](archive/2025-06/0619.md#AutoMind-Adaptive-Knowledgeable-Agent-for-Automated-Data-Science)
- [Specification and Evaluation of Multi-Agent LLM Systems -- Prototype and Cybersecurity Applications](archive/2025-06/0619.md#Specification-and-Evaluation-of-Multi-Agent-LLM-Systems----Prototype-and-Cybersecurity-Applications)

### 0605-0612

- [Edit Flows: Flow Matching with Edit Operations](archive/2025-06/0612.md#Edit-Flows-Flow-Matching-with-Edit-Operations)
- [SWE-Flow: Synthesizing Software Engineering Data in a Test-Driven Manner](archive/2025-06/0612.md#SWE-Flow-Synthesizing-Software-Engineering-Data-in-a-Test-Driven-Manner)
- [Draft-based Approximate Inference for LLMs](archive/2025-06/0612.md#Draft-based-Approximate-Inference-for-LLMs)
- [Understanding Software Engineering Agents Through the Lens of Traceability: An Empirical Study](archive/2025-06/0612.md#Understanding-Software-Engineering-Agents-Through-the-Lens-of-Traceability-An-Empirical-Study)
- [Repeton: Structured Bug Repair with ReAct-Guided Patch-and-Test Cycles](archive/2025-06/0612.md#Repeton-Structured-Bug-Repair-with-ReAct-Guided-Patch-and-Test-Cycles)
- [Worst-Case Symbolic Constraints Analysis and Generalisation with Large Language Models](archive/2025-06/0612.md#Worst-Case-Symbolic-Constraints-Analysis-and-Generalisation-with-Large-Language-Models)
- [AutoSDT: Scaling Data-Driven Discovery Tasks Toward Open Co-Scientists](archive/2025-06/0612.md#AutoSDT-Scaling-Data-Driven-Discovery-Tasks-Toward-Open-Co-Scientists)
- [SlideCoder: Layout-aware RAG-enhanced Hierarchical Slide Generation from Design](archive/2025-06/0612.md#SlideCoder-Layout-aware-RAG-enhanced-Hierarchical-Slide-Generation-from-Design)
- [ProtocolLLM: RTL Benchmark for SystemVerilog Generation of Communication Protocols](archive/2025-06/0612.md#ProtocolLLM-RTL-Benchmark-for-SystemVerilog-Generation-of-Communication-Protocols)
- [Learning to Focus: Causal Attention Distillation via Gradient-Guided Token Pruning](archive/2025-06/0612.md#Learning-to-Focus-Causal-Attention-Distillation-via-Gradient-Guided-Token-Pruning)
- [LiteVLM: A Low-Latency Vision-Language Model Inference Pipeline for Resource-Constrained Environments](archive/2025-06/0612.md#LiteVLM-A-Low-Latency-Vision-Language-Model-Inference-Pipeline-for-Resource-Constrained-Environments)
- [VeriLoC: Line-of-Code Level Prediction of Hardware Design Quality from Verilog Code](archive/2025-06/0612.md#VeriLoC-Line-of-Code-Level-Prediction-of-Hardware-Design-Quality-from-Verilog-Code)
- [Break-The-Chain: Reasoning Failures in LLMs via Adversarial Prompting in Code Generation](archive/2025-06/0612.md#Break-The-Chain-Reasoning-Failures-in-LLMs-via-Adversarial-Prompting-in-Code-Generation)
- [KnowCoder-V2: Deep Knowledge Analysis](archive/2025-06/0612.md#KnowCoder-V2-Deep-Knowledge-Analysis)
- [Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems](archive/2025-06/0612.md#Can-LLMs-Generate-Reliable-Test-Case-Generators-A-Study-on-Competition-Level-Programming-Problems)
- [Training-Free Tokenizer Transplantation via Orthogonal Matching Pursuit](archive/2025-06/0612.md#Training-Free-Tokenizer-Transplantation-via-Orthogonal-Matching-Pursuit)
- [KramaBench: A Benchmark for AI Systems on Data-to-Insight Pipelines over Data Lakes](archive/2025-06/0612.md#KramaBench-A-Benchmark-for-AI-Systems-on-Data-to-Insight-Pipelines-over-Data-Lakes)
- [DesignBench: A Comprehensive Benchmark for MLLM-based Front-end Code Generation](archive/2025-06/0612.md#DesignBench-A-Comprehensive-Benchmark-for-MLLM-based-Front-end-Code-Generation)
- [Can Theoretical Physics Research Benefit from Language Agents?](archive/2025-06/0612.md#Can-Theoretical-Physics-Research-Benefit-from-Language-Agents)
- [Table-r1: Self-supervised and Reinforcement Learning for Program-based Table Reasoning in Small Language Models](archive/2025-06/0612.md#Table-r1-Self-supervised-and-Reinforcement-Learning-for-Program-based-Table-Reasoning-in-Small-Language-Models)
- [Reinforcing Code Generation: Improving Text-to-SQL with Execution-Based Learning](archive/2025-06/0612.md#Reinforcing-Code-Generation-Improving-Text-to-SQL-with-Execution-Based-Learning)
- [CP-Bench: Evaluating Large Language Models for Constraint Modelling](archive/2025-06/0612.md#CP-Bench-Evaluating-Large-Language-Models-for-Constraint-Modelling)
- [SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code](archive/2025-06/0612.md#SafeGenBench-A-Benchmark-Framework-for-Security-Vulnerability-Detection-in-LLM-Generated-Code)
- [Deployability-Centric Infrastructure-as-Code Generation: An LLM-based Iterative Framework](archive/2025-06/0612.md#Deployability-Centric-Infrastructure-as-Code-Generation-An-LLM-based-Iterative-Framework)
- [Toward Greater Autonomy in Materials Discovery Agents: Unifying Planning, Physics, and Scientists](archive/2025-06/0612.md#Toward-Greater-Autonomy-in-Materials-Discovery-Agents-Unifying-Planning-Physics-and-Scientists)
- [ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation](archive/2025-06/0612.md#ScaleRTL-Scaling-LLMs-with-Reasoning-Data-and-Test-Time-Compute-for-Accurate-RTL-Code-Generation)
- [ICPC-Eval: Probing the Frontiers of LLM Reasoning with Competitive Programming Contests](archive/2025-06/0612.md#ICPC-Eval-Probing-the-Frontiers-of-LLM-Reasoning-with-Competitive-Programming-Contests)
- [Accelerated Test-Time Scaling with Model-Free Speculative Sampling](archive/2025-06/0612.md#Accelerated-Test-Time-Scaling-with-Model-Free-Speculative-Sampling)
- [Agents of Change: Self-Evolving LLM Agents for Strategic Planning](archive/2025-06/0612.md#Agents-of-Change-Self-Evolving-LLM-Agents-for-Strategic-Planning)
- [Demonstrations of Integrity Attacks in Multi-Agent Systems](archive/2025-06/0612.md#Demonstrations-of-Integrity-Attacks-in-Multi-Agent-Systems)
- [hdl2v: A Code Translation Dataset for Enhanced LLM Verilog Generation](archive/2025-06/0612.md#hdl2v-A-Code-Translation-Dataset-for-Enhanced-LLM-Verilog-Generation)

### 0528-0604

- [Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning](archive/2025-06/0604.md#Co-Evolving-LLM-Coder-and-Unit-Tester-via-Reinforcement-Learning)
- [Adaptive Graph Pruning for Multi-Agent Communication](archive/2025-06/0604.md#Adaptive-Graph-Pruning-for-Multi-Agent-Communication)
- [Rethinking the effects of data contamination in Code Intelligence](archive/2025-06/0604.md#Rethinking-the-effects-of-data-contamination-in-Code-Intelligence)
- [Consultant Decoding: Yet Another Synergistic Mechanism](archive/2025-06/0604.md#Consultant-Decoding-Yet-Another-Synergistic-Mechanism)
- [ResearchCodeBench: Benchmarking LLMs on Implementing Novel Machine Learning Research Code](archive/2025-06/0604.md#ResearchCodeBench-Benchmarking-LLMs-on-Implementing-Novel-Machine-Learning-Research-Code)
- [Improving LLM-Generated Code Quality with GRPO](archive/2025-06/0604.md#Improving-LLM-Generated-Code-Quality-with-GRPO)
- [SALAD: Systematic Assessment of Machine Unlearing on LLM-Aided Hardware Design](archive/2025-06/0604.md#SALAD-Systematic-Assessment-of-Machine-Unlearing-on-LLM-Aided-Hardware-Design)
- [Flow2Code: Evaluating Large Language Models for Flowchart-based Code Generation Capability](archive/2025-06/0604.md#Flow2Code-Evaluating-Large-Language-Models-for-Flowchart-based-Code-Generation-Capability)
- [DeepSeek in Healthcare: A Survey of Capabilities, Risks, and Clinical Applications of Open-Source Large Language Models](archive/2025-06/0604.md#DeepSeek-in-Healthcare-A-Survey-of-Capabilities-Risks-and-Clinical-Applications-of-Open-Source-Large-Language-Models)
- [Mamba Drafters for Speculative Decoding](archive/2025-06/0604.md#Mamba-Drafters-for-Speculative-Decoding)
- [XAI-Units: Benchmarking Explainability Methods with Unit Tests](archive/2025-06/0604.md#XAI-Units-Benchmarking-Explainability-Methods-with-Unit-Tests)
- [Legal Compliance Evaluation of Smart Contracts Generated By Large Language Models](archive/2025-06/0604.md#Legal-Compliance-Evaluation-of-Smart-Contracts-Generated-By-Large-Language-Models)
- [A "Wenlu" Brain System for Multimodal Cognition and Embodied Decision-Making: A Secure New Architecture for Deep Integration of Foundation Models and Domain Knowledge](archive/2025-06/0604.md#A-Wenlu-Brain-System-for-Multimodal-Cognition-and-Embodied-Decision-Making-A-Secure-New-Architecture-for-Deep-Integration-of-Foundation-Models-and-Domain-Knowledge)
- [Accelerating Diffusion LLMs via Adaptive Parallel Decoding](archive/2025-06/0604.md#Accelerating-Diffusion-LLMs-via-Adaptive-Parallel-Decoding)
- [Writing-Zero: Bridge the Gap Between Non-verifiable Problems and Verifiable Rewards](archive/2025-06/0604.md#Writing-Zero-Bridge-the-Gap-Between-Non-verifiable-Problems-and-Verifiable-Rewards)
- [Eye of Judgement: Dissecting the Evaluation of Russian-speaking LLMs with POLLUX](archive/2025-06/0604.md#Eye-of-Judgement-Dissecting-the-Evaluation-of-Russian-speaking-LLMs-with-POLLUX)
- [Cross-Attention Speculative Decoding](archive/2025-06/0604.md#Cross-Attention-Speculative-Decoding)
- [RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation](archive/2025-06/0604.md#RMoA-Optimizing-Mixture-of-Agents-through-Diversity-Maximization-and-Residual-Compensation)
- [SwiftEval: Developing a Language-Specific Benchmark for LLM-generated Code Evaluation](archive/2025-06/0604.md#SwiftEval-Developing-a-Language-Specific-Benchmark-for-LLM-generated-Code-Evaluation)
- [A Reward-driven Automated Webshell Malicious-code Generator for Red-teaming](archive/2025-06/0604.md#A-Reward-driven-Automated-Webshell-Malicious-code-Generator-for-Red-teaming)


## 2025-05 

### 0522-0529

- [Mitigating Overthinking in Large Reasoning Models via Manifold Steering](archive/2025-05/0529.md#Mitigating-Overthinking-in-Large-Reasoning-Models-via-Manifold-Steering)
- [Text2Grad: Reinforcement Learning from Natural Language Feedback](archive/2025-05/0529.md#Text2Grad-Reinforcement-Learning-from-Natural-Language-Feedback)
- [MRT at SemEval-2025 Task 8: Maximizing Recovery from Tables with Multiple Steps](archive/2025-05/0529.md#MRT-at-SemEval-2025-Task-8-Maximizing-Recovery-from-Tables-with-Multiple-Steps)
- [Speculative Decoding Meets Quantization: Compatibility Evaluation and Hierarchical Framework Design](archive/2025-05/0529.md#Speculative-Decoding-Meets-Quantization-Compatibility-Evaluation-and-Hierarchical-Framework-Design)
- [RAD: Redundancy-Aware Distillation for Hybrid Models via Self-Speculative Decoding](archive/2025-05/0529.md#RAD-Redundancy-Aware-Distillation-for-Hybrid-Models-via-Self-Speculative-Decoding)
- [From Coders to Critics: Empowering Students through Peer Assessment in the Age of AI Copilots](archive/2025-05/0529.md#From-Coders-to-Critics-Empowering-Students-through-Peer-Assessment-in-the-Age-of-AI-Copilots)
- [R1-Code-Interpreter: Training LLMs to Reason with Code via Supervised and Reinforcement Learning](archive/2025-05/0529.md#R1-Code-Interpreter-Training-LLMs-to-Reason-with-Code-via-Supervised-and-Reinforcement-Learning)
- [Hardware-Efficient Attention for Fast Decoding](archive/2025-05/0529.md#Hardware-Efficient-Attention-for-Fast-Decoding)
- [rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale Verified Dataset](archive/2025-05/0529.md#rStar-Coder-Scaling-Competitive-Code-Reasoning-with-a-Large-Scale-Verified-Dataset)
- [RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for Complex Task Solving](archive/2025-05/0529.md#RepoMaster-Autonomous-Exploration-and-Understanding-of-GitHub-Repositories-for-Complex-Task-Solving)
- [An LLM-as-Judge Metric for Bridging the Gap with Human Evaluation in SE Tasks](archive/2025-05/0529.md#An-LLM-as-Judge-Metric-for-Bridging-the-Gap-with-Human-Evaluation-in-SE-Tasks)
- [Rendering-Aware Reinforcement Learning for Vector Graphics Generation](archive/2025-05/0529.md#Rendering-Aware-Reinforcement-Learning-for-Vector-Graphics-Generation)
- [SpecExtend: A Drop-in Enhancement for Speculative Decoding of Long Sequences](archive/2025-05/0529.md#SpecExtend-A-Drop-in-Enhancement-for-Speculative-Decoding-of-Long-Sequences)
- [AutoReproduce: Automatic AI Experiment Reproduction with Paper Lineage](archive/2025-05/0529.md#AutoReproduce-Automatic-AI-Experiment-Reproduction-with-Paper-Lineage)
- [Large Language Models for IT Automation Tasks: Are We There Yet?](archive/2025-05/0529.md#Large-Language-Models-for-IT-Automation-Tasks-Are-We-There-Yet)
- [HAMburger: Accelerating LLM Inference via Token Smashing](archive/2025-05/0529.md#HAMburger-Accelerating-LLM-Inference-via-Token-Smashing)
- [SWE-rebench: An Automated Pipeline for Task Collection and Decontaminated Evaluation of Software Engineering Agents](archive/2025-05/0529.md#SWE-rebench-An-Automated-Pipeline-for-Task-Collection-and-Decontaminated-Evaluation-of-Software-Engineering-Agents)
- [An Empirical Study on Strong-Weak Model Collaboration for Repo-level Code Generation](archive/2025-05/0529.md#An-Empirical-Study-on-Strong-Weak-Model-Collaboration-for-Repo-level-Code-Generation)
- [Compliance-to-Code: Enhancing Financial Compliance Checking via Code Generation](archive/2025-05/0529.md#Compliance-to-Code-Enhancing-Financial-Compliance-Checking-via-Code-Generation)
- [ReChisel: Effective Automatic Chisel Code Generation by LLM with Reflection](archive/2025-05/0529.md#ReChisel-Effective-Automatic-Chisel-Code-Generation-by-LLM-with-Reflection)

### 0515-0522

- [Learning to Reason via Mixture-of-Thought for Logical Reasoning](archive/2025-05/0522.md#Learning-to-Reason-via-Mixture-of-Thought-for-Logical-Reasoning)
- [Long-Form Information Alignment Evaluation Beyond Atomic Facts](archive/2025-05/0522.md#Long-Form-Information-Alignment-Evaluation-Beyond-Atomic-Facts)
- [Large Language Models as Computable Approximations to Solomonoff Induction](archive/2025-05/0522.md#Large-Language-Models-as-Computable-Approximations-to-Solomonoff-Induction)
- [dKV-Cache: The Cache for Diffusion Language Models](archive/2025-05/0522.md#dKV-Cache-The-Cache-for-Diffusion-Language-Models)
- [Soft Thinking: Unlocking the Reasoning Potential of LLMs in Continuous Concept Space](archive/2025-05/0522.md#Soft-Thinking-Unlocking-the-Reasoning-Potential-of-LLMs-in-Continuous-Concept-Space)
- [Scalable Defense against In-the-wild Jailbreaking Attacks with Safety Context Retrieval](archive/2025-05/0522.md#Scalable-Defense-against-In-the-wild-Jailbreaking-Attacks-with-Safety-Context-Retrieval)
- [HybridProver: Augmenting Theorem Proving with LLM-Driven Proof Synthesis and Refinement](archive/2025-05/0522.md#HybridProver-Augmenting-Theorem-Proving-with-LLM-Driven-Proof-Synthesis-and-Refinement)
- [VocalBench: Benchmarking the Vocal Conversational Abilities for Speech Interaction Models](archive/2025-05/0522.md#VocalBench-Benchmarking-the-Vocal-Conversational-Abilities-for-Speech-Interaction-Models)
- [Advancing LLM Safe Alignment with Safety Representation Ranking](archive/2025-05/0522.md#Advancing-LLM-Safe-Alignment-with-Safety-Representation-Ranking)
- [LyapLock: Bounded Knowledge Preservation in Sequential Large Language Model Editing](archive/2025-05/0522.md#LyapLock-Bounded-Knowledge-Preservation-in-Sequential-Large-Language-Model-Editing)
- [HDLxGraph: Bridging Large Language Models and HDL Repositories via HDL Graph Databases](archive/2025-05/0522.md#HDLxGraph-Bridging-Large-Language-Models-and-HDL-Repositories-via-HDL-Graph-Databases)
- [Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model](archive/2025-05/0522.md#Efficient-and-Direct-Duplex-Modeling-for-Speech-to-Speech-Language-Model)
- [Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data Could Be Secretly Stolen!](archive/2025-05/0522.md#Be-Careful-When-Fine-tuning-On-Open-Source-LLMs-Your-Fine-tuning-Data-Could-Be-Secretly-Stolen)
- [Guidelines for the Quality Assessment of Energy-Aware NAS Benchmarks](archive/2025-05/0522.md#Guidelines-for-the-Quality-Assessment-of-Energy-Aware-NAS-Benchmarks)
- [DS-Bench: A Realistic Benchmark for Data Science Code Generation](archive/2025-05/0522.md#DS-Bench-A-Realistic-Benchmark-for-Data-Science-Code-Generation)
- [Deep Learning for Continuous-time Stochastic Control with Jumps](archive/2025-05/0522.md#Deep-Learning-for-Continuous-time-Stochastic-Control-with-Jumps)
- [UWSAM: Segment Anything Model Guided Underwater Instance Segmentation and A Large-scale Benchmark Dataset](archive/2025-05/0522.md#UWSAM-Segment-Anything-Model-Guided-Underwater-Instance-Segmentation-and-A-Large-scale-Benchmark-Dataset)
- [Visual Perturbation and Adaptive Hard Negative Contrastive Learning for Compositional Reasoning in Vision-Language Models](archive/2025-05/0522.md#Visual-Perturbation-and-Adaptive-Hard-Negative-Contrastive-Learning-for-Compositional-Reasoning-in-Vision-Language-Models)
- [Bridging the Domain Gap in Equation Distillation with Reinforcement Feedback](archive/2025-05/0522.md#Bridging-the-Domain-Gap-in-Equation-Distillation-with-Reinforcement-Feedback)
- [Moonbeam: A MIDI Foundation Model Using Both Absolute and Relative Music Attributes](archive/2025-05/0522.md#Moonbeam-A-MIDI-Foundation-Model-Using-Both-Absolute-and-Relative-Music-Attributes)
