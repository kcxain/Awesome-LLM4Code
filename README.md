

## 2025-06 

### 0528-0604

- [Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning](archive/2025-06/0604.md#Co-Evolving-LLM-Coder-and-Unit-Tester-via-Reinforcement-Learning)
- [Adaptive Graph Pruning for Multi-Agent Communication](archive/2025-06/0604.md#Adaptive-Graph-Pruning-for-Multi-Agent-Communication)
- [Rethinking the effects of data contamination in Code Intelligence](archive/2025-06/0604.md#Rethinking-the-effects-of-data-contamination-in-Code-Intelligence)
- [Consultant Decoding: Yet Another Synergistic Mechanism](archive/2025-06/0604.md#Consultant-Decoding-Yet-Another-Synergistic-Mechanism)
- [ResearchCodeBench: Benchmarking LLMs on Implementing Novel Machine Learning Research Code](archive/2025-06/0604.md#ResearchCodeBench-Benchmarking-LLMs-on-Implementing-Novel-Machine-Learning-Research-Code)
- [Improving LLM-Generated Code Quality with GRPO](archive/2025-06/0604.md#Improving-LLM-Generated-Code-Quality-with-GRPO)
- [SALAD: Systematic Assessment of Machine Unlearing on LLM-Aided Hardware Design](archive/2025-06/0604.md#SALAD-Systematic-Assessment-of-Machine-Unlearing-on-LLM-Aided-Hardware-Design)
- [Flow2Code: Evaluating Large Language Models for Flowchart-based Code Generation Capability](archive/2025-06/0604.md#Flow2Code-Evaluating-Large-Language-Models-for-Flowchart-based-Code-Generation-Capability)
- [DeepSeek in Healthcare: A Survey of Capabilities, Risks, and Clinical Applications of Open-Source Large Language Models](archive/2025-06/0604.md#DeepSeek-in-Healthcare-A-Survey-of-Capabilities-Risks-and-Clinical-Applications-of-Open-Source-Large-Language-Models)
- [Mamba Drafters for Speculative Decoding](archive/2025-06/0604.md#Mamba-Drafters-for-Speculative-Decoding)
- [XAI-Units: Benchmarking Explainability Methods with Unit Tests](archive/2025-06/0604.md#XAI-Units-Benchmarking-Explainability-Methods-with-Unit-Tests)
- [Legal Compliance Evaluation of Smart Contracts Generated By Large Language Models](archive/2025-06/0604.md#Legal-Compliance-Evaluation-of-Smart-Contracts-Generated-By-Large-Language-Models)
- [A "Wenlu" Brain System for Multimodal Cognition and Embodied Decision-Making: A Secure New Architecture for Deep Integration of Foundation Models and Domain Knowledge](archive/2025-06/0604.md#A-Wenlu-Brain-System-for-Multimodal-Cognition-and-Embodied-Decision-Making-A-Secure-New-Architecture-for-Deep-Integration-of-Foundation-Models-and-Domain-Knowledge)
- [Accelerating Diffusion LLMs via Adaptive Parallel Decoding](archive/2025-06/0604.md#Accelerating-Diffusion-LLMs-via-Adaptive-Parallel-Decoding)
- [Writing-Zero: Bridge the Gap Between Non-verifiable Problems and Verifiable Rewards](archive/2025-06/0604.md#Writing-Zero-Bridge-the-Gap-Between-Non-verifiable-Problems-and-Verifiable-Rewards)
- [Eye of Judgement: Dissecting the Evaluation of Russian-speaking LLMs with POLLUX](archive/2025-06/0604.md#Eye-of-Judgement-Dissecting-the-Evaluation-of-Russian-speaking-LLMs-with-POLLUX)
- [Cross-Attention Speculative Decoding](archive/2025-06/0604.md#Cross-Attention-Speculative-Decoding)
- [RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation](archive/2025-06/0604.md#RMoA-Optimizing-Mixture-of-Agents-through-Diversity-Maximization-and-Residual-Compensation)
- [SwiftEval: Developing a Language-Specific Benchmark for LLM-generated Code Evaluation](archive/2025-06/0604.md#SwiftEval-Developing-a-Language-Specific-Benchmark-for-LLM-generated-Code-Evaluation)
- [A Reward-driven Automated Webshell Malicious-code Generator for Red-teaming](archive/2025-06/0604.md#A-Reward-driven-Automated-Webshell-Malicious-code-Generator-for-Red-teaming)
# Awesome-LLM4Code



## 2025-05 

### 0522-0529

- [Mitigating Overthinking in Large Reasoning Models via Manifold Steering](archive/2025-05/0529.md#Mitigating-Overthinking-in-Large-Reasoning-Models-via-Manifold-Steering)
- [Text2Grad: Reinforcement Learning from Natural Language Feedback](archive/2025-05/0529.md#Text2Grad-Reinforcement-Learning-from-Natural-Language-Feedback)
- [MRT at SemEval-2025 Task 8: Maximizing Recovery from Tables with Multiple Steps](archive/2025-05/0529.md#MRT-at-SemEval-2025-Task-8-Maximizing-Recovery-from-Tables-with-Multiple-Steps)
- [Speculative Decoding Meets Quantization: Compatibility Evaluation and Hierarchical Framework Design](archive/2025-05/0529.md#Speculative-Decoding-Meets-Quantization-Compatibility-Evaluation-and-Hierarchical-Framework-Design)
- [RAD: Redundancy-Aware Distillation for Hybrid Models via Self-Speculative Decoding](archive/2025-05/0529.md#RAD-Redundancy-Aware-Distillation-for-Hybrid-Models-via-Self-Speculative-Decoding)
- [From Coders to Critics: Empowering Students through Peer Assessment in the Age of AI Copilots](archive/2025-05/0529.md#From-Coders-to-Critics-Empowering-Students-through-Peer-Assessment-in-the-Age-of-AI-Copilots)
- [R1-Code-Interpreter: Training LLMs to Reason with Code via Supervised and Reinforcement Learning](archive/2025-05/0529.md#R1-Code-Interpreter-Training-LLMs-to-Reason-with-Code-via-Supervised-and-Reinforcement-Learning)
- [Hardware-Efficient Attention for Fast Decoding](archive/2025-05/0529.md#Hardware-Efficient-Attention-for-Fast-Decoding)
- [rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale Verified Dataset](archive/2025-05/0529.md#rStar-Coder-Scaling-Competitive-Code-Reasoning-with-a-Large-Scale-Verified-Dataset)
- [RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for Complex Task Solving](archive/2025-05/0529.md#RepoMaster-Autonomous-Exploration-and-Understanding-of-GitHub-Repositories-for-Complex-Task-Solving)
- [An LLM-as-Judge Metric for Bridging the Gap with Human Evaluation in SE Tasks](archive/2025-05/0529.md#An-LLM-as-Judge-Metric-for-Bridging-the-Gap-with-Human-Evaluation-in-SE-Tasks)
- [Rendering-Aware Reinforcement Learning for Vector Graphics Generation](archive/2025-05/0529.md#Rendering-Aware-Reinforcement-Learning-for-Vector-Graphics-Generation)
- [SpecExtend: A Drop-in Enhancement for Speculative Decoding of Long Sequences](archive/2025-05/0529.md#SpecExtend-A-Drop-in-Enhancement-for-Speculative-Decoding-of-Long-Sequences)
- [AutoReproduce: Automatic AI Experiment Reproduction with Paper Lineage](archive/2025-05/0529.md#AutoReproduce-Automatic-AI-Experiment-Reproduction-with-Paper-Lineage)
- [Large Language Models for IT Automation Tasks: Are We There Yet?](archive/2025-05/0529.md#Large-Language-Models-for-IT-Automation-Tasks-Are-We-There-Yet)
- [HAMburger: Accelerating LLM Inference via Token Smashing](archive/2025-05/0529.md#HAMburger-Accelerating-LLM-Inference-via-Token-Smashing)
- [SWE-rebench: An Automated Pipeline for Task Collection and Decontaminated Evaluation of Software Engineering Agents](archive/2025-05/0529.md#SWE-rebench-An-Automated-Pipeline-for-Task-Collection-and-Decontaminated-Evaluation-of-Software-Engineering-Agents)
- [An Empirical Study on Strong-Weak Model Collaboration for Repo-level Code Generation](archive/2025-05/0529.md#An-Empirical-Study-on-Strong-Weak-Model-Collaboration-for-Repo-level-Code-Generation)
- [Compliance-to-Code: Enhancing Financial Compliance Checking via Code Generation](archive/2025-05/0529.md#Compliance-to-Code-Enhancing-Financial-Compliance-Checking-via-Code-Generation)
- [ReChisel: Effective Automatic Chisel Code Generation by LLM with Reflection](archive/2025-05/0529.md#ReChisel-Effective-Automatic-Chisel-Code-Generation-by-LLM-with-Reflection)

### 0515-0522

- [Learning to Reason via Mixture-of-Thought for Logical Reasoning](archive/2025-05/0522.md#Learning-to-Reason-via-Mixture-of-Thought-for-Logical-Reasoning)
- [Long-Form Information Alignment Evaluation Beyond Atomic Facts](archive/2025-05/0522.md#Long-Form-Information-Alignment-Evaluation-Beyond-Atomic-Facts)
- [Large Language Models as Computable Approximations to Solomonoff Induction](archive/2025-05/0522.md#Large-Language-Models-as-Computable-Approximations-to-Solomonoff-Induction)
- [dKV-Cache: The Cache for Diffusion Language Models](archive/2025-05/0522.md#dKV-Cache-The-Cache-for-Diffusion-Language-Models)
- [Soft Thinking: Unlocking the Reasoning Potential of LLMs in Continuous Concept Space](archive/2025-05/0522.md#Soft-Thinking-Unlocking-the-Reasoning-Potential-of-LLMs-in-Continuous-Concept-Space)
- [Scalable Defense against In-the-wild Jailbreaking Attacks with Safety Context Retrieval](archive/2025-05/0522.md#Scalable-Defense-against-In-the-wild-Jailbreaking-Attacks-with-Safety-Context-Retrieval)
- [HybridProver: Augmenting Theorem Proving with LLM-Driven Proof Synthesis and Refinement](archive/2025-05/0522.md#HybridProver-Augmenting-Theorem-Proving-with-LLM-Driven-Proof-Synthesis-and-Refinement)
- [VocalBench: Benchmarking the Vocal Conversational Abilities for Speech Interaction Models](archive/2025-05/0522.md#VocalBench-Benchmarking-the-Vocal-Conversational-Abilities-for-Speech-Interaction-Models)
- [Advancing LLM Safe Alignment with Safety Representation Ranking](archive/2025-05/0522.md#Advancing-LLM-Safe-Alignment-with-Safety-Representation-Ranking)
- [LyapLock: Bounded Knowledge Preservation in Sequential Large Language Model Editing](archive/2025-05/0522.md#LyapLock-Bounded-Knowledge-Preservation-in-Sequential-Large-Language-Model-Editing)
- [HDLxGraph: Bridging Large Language Models and HDL Repositories via HDL Graph Databases](archive/2025-05/0522.md#HDLxGraph-Bridging-Large-Language-Models-and-HDL-Repositories-via-HDL-Graph-Databases)
- [Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model](archive/2025-05/0522.md#Efficient-and-Direct-Duplex-Modeling-for-Speech-to-Speech-Language-Model)
- [Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data Could Be Secretly Stolen!](archive/2025-05/0522.md#Be-Careful-When-Fine-tuning-On-Open-Source-LLMs-Your-Fine-tuning-Data-Could-Be-Secretly-Stolen)
- [Guidelines for the Quality Assessment of Energy-Aware NAS Benchmarks](archive/2025-05/0522.md#Guidelines-for-the-Quality-Assessment-of-Energy-Aware-NAS-Benchmarks)
- [DS-Bench: A Realistic Benchmark for Data Science Code Generation](archive/2025-05/0522.md#DS-Bench-A-Realistic-Benchmark-for-Data-Science-Code-Generation)
- [Deep Learning for Continuous-time Stochastic Control with Jumps](archive/2025-05/0522.md#Deep-Learning-for-Continuous-time-Stochastic-Control-with-Jumps)
- [UWSAM: Segment Anything Model Guided Underwater Instance Segmentation and A Large-scale Benchmark Dataset](archive/2025-05/0522.md#UWSAM-Segment-Anything-Model-Guided-Underwater-Instance-Segmentation-and-A-Large-scale-Benchmark-Dataset)
- [Visual Perturbation and Adaptive Hard Negative Contrastive Learning for Compositional Reasoning in Vision-Language Models](archive/2025-05/0522.md#Visual-Perturbation-and-Adaptive-Hard-Negative-Contrastive-Learning-for-Compositional-Reasoning-in-Vision-Language-Models)
- [Bridging the Domain Gap in Equation Distillation with Reinforcement Feedback](archive/2025-05/0522.md#Bridging-the-Domain-Gap-in-Equation-Distillation-with-Reinforcement-Feedback)
- [Moonbeam: A MIDI Foundation Model Using Both Absolute and Relative Music Attributes](archive/2025-05/0522.md#Moonbeam-A-MIDI-Foundation-Model-Using-Both-Absolute-and-Relative-Music-Attributes)
