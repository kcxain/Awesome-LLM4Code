# Awesome-LLM4Code




## 2025-06 

##### 0612-0619

- [Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and Training Factors Shape LLM Alignment Quality](archive/2025-06/0619.md#Massive-Supervised-Fine-tuning-Experiments-Reveal-How-Data-Layer-and-Training-Factors-Shape-LLM-Alignment-Quality)
- [StreetLens: Enabling Human-Centered AI Agents for Neighborhood Assessment from Street View Imagery](archive/2025-06/0619.md#StreetLens-Enabling-Human-Centered-AI-Agents-for-Neighborhood-Assessment-from-Street-View-Imagery)
- [Guaranteed Guess: A Language Modeling Approach for CISC-to-RISC Transpilation with Testing Guarantees](archive/2025-06/0619.md#Guaranteed-Guess-A-Language-Modeling-Approach-for-CISC-to-RISC-Transpilation-with-Testing-Guarantees)
- [Sampling from Your Language Model One Byte at a Time](archive/2025-06/0619.md#Sampling-from-Your-Language-Model-One-Byte-at-a-Time)
- [How Does LLM Reasoning Work for Code? A Survey and a Call to Action](archive/2025-06/0619.md#How-Does-LLM-Reasoning-Work-for-Code-A-Survey-and-a-Call-to-Action)
- [LocationReasoner: Evaluating LLMs on Real-World Site Selection Reasoning](archive/2025-06/0619.md#LocationReasoner-Evaluating-LLMs-on-Real-World-Site-Selection-Reasoning)
- [A Technical Study into Small Reasoning Language Models](archive/2025-06/0619.md#A-Technical-Study-into-Small-Reasoning-Language-Models)
- [FrontendBench: A Benchmark for Evaluating LLMs on Front-End Development via Automatic Evaluation](archive/2025-06/0619.md#FrontendBench-A-Benchmark-for-Evaluating-LLMs-on-Front-End-Development-via-Automatic-Evaluation)
- [Structured Program Synthesis using LLMs: Results and Insights from the IPARC Challenge](archive/2025-06/0619.md#Structured-Program-Synthesis-using-LLMs-Results-and-Insights-from-the-IPARC-Challenge)
- [Humanity's Last Code Exam: Can Advanced LLMs Conquer Human's Hardest Code Competition?](archive/2025-06/0619.md#Humanitys-Last-Code-Exam-Can-Advanced-LLMs-Conquer-Humans-Hardest-Code-Competition)
- [QiMeng-Attention: SOTA Attention Operator is generated by SOTA Attention Algorithm](archive/2025-06/0619.md#QiMeng-Attention-SOTA-Attention-Operator-is-generated-by-SOTA-Attention-Algorithm)
- [PRO-V: An Efficient Program Generation Multi-Agent System for Automatic RTL Verification](archive/2025-06/0619.md#PRO-V-An-Efficient-Program-Generation-Multi-Agent-System-for-Automatic-RTL-Verification)
- [code_transformed: The Influence of Large Language Models on Code](archive/2025-06/0619.md#code_transformed-The-Influence-of-Large-Language-Models-on-Code)
- [Configurable Preference Tuning with Rubric-Guided Synthetic Data](archive/2025-06/0619.md#Configurable-Preference-Tuning-with-Rubric-Guided-Synthetic-Data)
- [Leveraging GPT-4 for Vulnerability-Witnessing Unit Test Generation](archive/2025-06/0619.md#Leveraging-GPT-4-for-Vulnerability-Witnessing-Unit-Test-Generation)
- [Agent-RLVR: Training Software Engineering Agents via Guidance and Environment Rewards](archive/2025-06/0619.md#Agent-RLVR-Training-Software-Engineering-Agents-via-Guidance-and-Environment-Rewards)
- [LLM-as-a-Judge for Reference-less Automatic Code Validation and Refinement for Natural Language to Bash in IT Automation](archive/2025-06/0619.md#LLM-as-a-Judge-for-Reference-less-Automatic-Code-Validation-and-Refinement-for-Natural-Language-to-Bash-in-IT-Automation)
- [AutoMind: Adaptive Knowledgeable Agent for Automated Data Science](archive/2025-06/0619.md#AutoMind-Adaptive-Knowledgeable-Agent-for-Automated-Data-Science)
- [Specification and Evaluation of Multi-Agent LLM Systems -- Prototype and Cybersecurity Applications](archive/2025-06/0619.md#Specification-and-Evaluation-of-Multi-Agent-LLM-Systems----Prototype-and-Cybersecurity-Applications)
# 0605-0612

- [Edit Flows: Flow Matching with Edit Operations](archive/2025-06/0612.md#Edit-Flows-Flow-Matching-with-Edit-Operations)
- [SWE-Flow: Synthesizing Software Engineering Data in a Test-Driven Manner](archive/2025-06/0612.md#SWE-Flow-Synthesizing-Software-Engineering-Data-in-a-Test-Driven-Manner)
- [Draft-based Approximate Inference for LLMs](archive/2025-06/0612.md#Draft-based-Approximate-Inference-for-LLMs)
- [Understanding Software Engineering Agents Through the Lens of Traceability: An Empirical Study](archive/2025-06/0612.md#Understanding-Software-Engineering-Agents-Through-the-Lens-of-Traceability-An-Empirical-Study)
- [Repeton: Structured Bug Repair with ReAct-Guided Patch-and-Test Cycles](archive/2025-06/0612.md#Repeton-Structured-Bug-Repair-with-ReAct-Guided-Patch-and-Test-Cycles)
- [Worst-Case Symbolic Constraints Analysis and Generalisation with Large Language Models](archive/2025-06/0612.md#Worst-Case-Symbolic-Constraints-Analysis-and-Generalisation-with-Large-Language-Models)
- [AutoSDT: Scaling Data-Driven Discovery Tasks Toward Open Co-Scientists](archive/2025-06/0612.md#AutoSDT-Scaling-Data-Driven-Discovery-Tasks-Toward-Open-Co-Scientists)
- [SlideCoder: Layout-aware RAG-enhanced Hierarchical Slide Generation from Design](archive/2025-06/0612.md#SlideCoder-Layout-aware-RAG-enhanced-Hierarchical-Slide-Generation-from-Design)
- [ProtocolLLM: RTL Benchmark for SystemVerilog Generation of Communication Protocols](archive/2025-06/0612.md#ProtocolLLM-RTL-Benchmark-for-SystemVerilog-Generation-of-Communication-Protocols)
- [Learning to Focus: Causal Attention Distillation via Gradient-Guided Token Pruning](archive/2025-06/0612.md#Learning-to-Focus-Causal-Attention-Distillation-via-Gradient-Guided-Token-Pruning)
- [LiteVLM: A Low-Latency Vision-Language Model Inference Pipeline for Resource-Constrained Environments](archive/2025-06/0612.md#LiteVLM-A-Low-Latency-Vision-Language-Model-Inference-Pipeline-for-Resource-Constrained-Environments)
- [VeriLoC: Line-of-Code Level Prediction of Hardware Design Quality from Verilog Code](archive/2025-06/0612.md#VeriLoC-Line-of-Code-Level-Prediction-of-Hardware-Design-Quality-from-Verilog-Code)
- [Break-The-Chain: Reasoning Failures in LLMs via Adversarial Prompting in Code Generation](archive/2025-06/0612.md#Break-The-Chain-Reasoning-Failures-in-LLMs-via-Adversarial-Prompting-in-Code-Generation)
- [KnowCoder-V2: Deep Knowledge Analysis](archive/2025-06/0612.md#KnowCoder-V2-Deep-Knowledge-Analysis)
- [Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems](archive/2025-06/0612.md#Can-LLMs-Generate-Reliable-Test-Case-Generators-A-Study-on-Competition-Level-Programming-Problems)
- [Training-Free Tokenizer Transplantation via Orthogonal Matching Pursuit](archive/2025-06/0612.md#Training-Free-Tokenizer-Transplantation-via-Orthogonal-Matching-Pursuit)
- [KramaBench: A Benchmark for AI Systems on Data-to-Insight Pipelines over Data Lakes](archive/2025-06/0612.md#KramaBench-A-Benchmark-for-AI-Systems-on-Data-to-Insight-Pipelines-over-Data-Lakes)
- [DesignBench: A Comprehensive Benchmark for MLLM-based Front-end Code Generation](archive/2025-06/0612.md#DesignBench-A-Comprehensive-Benchmark-for-MLLM-based-Front-end-Code-Generation)
- [Can Theoretical Physics Research Benefit from Language Agents?](archive/2025-06/0612.md#Can-Theoretical-Physics-Research-Benefit-from-Language-Agents)
- [Table-r1: Self-supervised and Reinforcement Learning for Program-based Table Reasoning in Small Language Models](archive/2025-06/0612.md#Table-r1-Self-supervised-and-Reinforcement-Learning-for-Program-based-Table-Reasoning-in-Small-Language-Models)
- [Reinforcing Code Generation: Improving Text-to-SQL with Execution-Based Learning](archive/2025-06/0612.md#Reinforcing-Code-Generation-Improving-Text-to-SQL-with-Execution-Based-Learning)
- [CP-Bench: Evaluating Large Language Models for Constraint Modelling](archive/2025-06/0612.md#CP-Bench-Evaluating-Large-Language-Models-for-Constraint-Modelling)
- [SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code](archive/2025-06/0612.md#SafeGenBench-A-Benchmark-Framework-for-Security-Vulnerability-Detection-in-LLM-Generated-Code)
- [Deployability-Centric Infrastructure-as-Code Generation: An LLM-based Iterative Framework](archive/2025-06/0612.md#Deployability-Centric-Infrastructure-as-Code-Generation-An-LLM-based-Iterative-Framework)
- [Toward Greater Autonomy in Materials Discovery Agents: Unifying Planning, Physics, and Scientists](archive/2025-06/0612.md#Toward-Greater-Autonomy-in-Materials-Discovery-Agents-Unifying-Planning-Physics-and-Scientists)
- [ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation](archive/2025-06/0612.md#ScaleRTL-Scaling-LLMs-with-Reasoning-Data-and-Test-Time-Compute-for-Accurate-RTL-Code-Generation)
- [ICPC-Eval: Probing the Frontiers of LLM Reasoning with Competitive Programming Contests](archive/2025-06/0612.md#ICPC-Eval-Probing-the-Frontiers-of-LLM-Reasoning-with-Competitive-Programming-Contests)
- [Accelerated Test-Time Scaling with Model-Free Speculative Sampling](archive/2025-06/0612.md#Accelerated-Test-Time-Scaling-with-Model-Free-Speculative-Sampling)
- [Agents of Change: Self-Evolving LLM Agents for Strategic Planning](archive/2025-06/0612.md#Agents-of-Change-Self-Evolving-LLM-Agents-for-Strategic-Planning)
- [Demonstrations of Integrity Attacks in Multi-Agent Systems](archive/2025-06/0612.md#Demonstrations-of-Integrity-Attacks-in-Multi-Agent-Systems)
- [hdl2v: A Code Translation Dataset for Enhanced LLM Verilog Generation](archive/2025-06/0612.md#hdl2v-A-Code-Translation-Dataset-for-Enhanced-LLM-Verilog-Generation)

### 0528-0604

- [Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning](archive/2025-06/0604.md#Co-Evolving-LLM-Coder-and-Unit-Tester-via-Reinforcement-Learning)
- [Adaptive Graph Pruning for Multi-Agent Communication](archive/2025-06/0604.md#Adaptive-Graph-Pruning-for-Multi-Agent-Communication)
- [Rethinking the effects of data contamination in Code Intelligence](archive/2025-06/0604.md#Rethinking-the-effects-of-data-contamination-in-Code-Intelligence)
- [Consultant Decoding: Yet Another Synergistic Mechanism](archive/2025-06/0604.md#Consultant-Decoding-Yet-Another-Synergistic-Mechanism)
- [ResearchCodeBench: Benchmarking LLMs on Implementing Novel Machine Learning Research Code](archive/2025-06/0604.md#ResearchCodeBench-Benchmarking-LLMs-on-Implementing-Novel-Machine-Learning-Research-Code)
- [Improving LLM-Generated Code Quality with GRPO](archive/2025-06/0604.md#Improving-LLM-Generated-Code-Quality-with-GRPO)
- [SALAD: Systematic Assessment of Machine Unlearing on LLM-Aided Hardware Design](archive/2025-06/0604.md#SALAD-Systematic-Assessment-of-Machine-Unlearing-on-LLM-Aided-Hardware-Design)
- [Flow2Code: Evaluating Large Language Models for Flowchart-based Code Generation Capability](archive/2025-06/0604.md#Flow2Code-Evaluating-Large-Language-Models-for-Flowchart-based-Code-Generation-Capability)
- [DeepSeek in Healthcare: A Survey of Capabilities, Risks, and Clinical Applications of Open-Source Large Language Models](archive/2025-06/0604.md#DeepSeek-in-Healthcare-A-Survey-of-Capabilities-Risks-and-Clinical-Applications-of-Open-Source-Large-Language-Models)
- [Mamba Drafters for Speculative Decoding](archive/2025-06/0604.md#Mamba-Drafters-for-Speculative-Decoding)
- [XAI-Units: Benchmarking Explainability Methods with Unit Tests](archive/2025-06/0604.md#XAI-Units-Benchmarking-Explainability-Methods-with-Unit-Tests)
- [Legal Compliance Evaluation of Smart Contracts Generated By Large Language Models](archive/2025-06/0604.md#Legal-Compliance-Evaluation-of-Smart-Contracts-Generated-By-Large-Language-Models)
- [A "Wenlu" Brain System for Multimodal Cognition and Embodied Decision-Making: A Secure New Architecture for Deep Integration of Foundation Models and Domain Knowledge](archive/2025-06/0604.md#A-Wenlu-Brain-System-for-Multimodal-Cognition-and-Embodied-Decision-Making-A-Secure-New-Architecture-for-Deep-Integration-of-Foundation-Models-and-Domain-Knowledge)
- [Accelerating Diffusion LLMs via Adaptive Parallel Decoding](archive/2025-06/0604.md#Accelerating-Diffusion-LLMs-via-Adaptive-Parallel-Decoding)
- [Writing-Zero: Bridge the Gap Between Non-verifiable Problems and Verifiable Rewards](archive/2025-06/0604.md#Writing-Zero-Bridge-the-Gap-Between-Non-verifiable-Problems-and-Verifiable-Rewards)
- [Eye of Judgement: Dissecting the Evaluation of Russian-speaking LLMs with POLLUX](archive/2025-06/0604.md#Eye-of-Judgement-Dissecting-the-Evaluation-of-Russian-speaking-LLMs-with-POLLUX)
- [Cross-Attention Speculative Decoding](archive/2025-06/0604.md#Cross-Attention-Speculative-Decoding)
- [RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation](archive/2025-06/0604.md#RMoA-Optimizing-Mixture-of-Agents-through-Diversity-Maximization-and-Residual-Compensation)
- [SwiftEval: Developing a Language-Specific Benchmark for LLM-generated Code Evaluation](archive/2025-06/0604.md#SwiftEval-Developing-a-Language-Specific-Benchmark-for-LLM-generated-Code-Evaluation)
- [A Reward-driven Automated Webshell Malicious-code Generator for Red-teaming](archive/2025-06/0604.md#A-Reward-driven-Automated-Webshell-Malicious-code-Generator-for-Red-teaming)


## 2025-05 

### 0522-0529

- [Mitigating Overthinking in Large Reasoning Models via Manifold Steering](archive/2025-05/0529.md#Mitigating-Overthinking-in-Large-Reasoning-Models-via-Manifold-Steering)
- [Text2Grad: Reinforcement Learning from Natural Language Feedback](archive/2025-05/0529.md#Text2Grad-Reinforcement-Learning-from-Natural-Language-Feedback)
- [MRT at SemEval-2025 Task 8: Maximizing Recovery from Tables with Multiple Steps](archive/2025-05/0529.md#MRT-at-SemEval-2025-Task-8-Maximizing-Recovery-from-Tables-with-Multiple-Steps)
- [Speculative Decoding Meets Quantization: Compatibility Evaluation and Hierarchical Framework Design](archive/2025-05/0529.md#Speculative-Decoding-Meets-Quantization-Compatibility-Evaluation-and-Hierarchical-Framework-Design)
- [RAD: Redundancy-Aware Distillation for Hybrid Models via Self-Speculative Decoding](archive/2025-05/0529.md#RAD-Redundancy-Aware-Distillation-for-Hybrid-Models-via-Self-Speculative-Decoding)
- [From Coders to Critics: Empowering Students through Peer Assessment in the Age of AI Copilots](archive/2025-05/0529.md#From-Coders-to-Critics-Empowering-Students-through-Peer-Assessment-in-the-Age-of-AI-Copilots)
- [R1-Code-Interpreter: Training LLMs to Reason with Code via Supervised and Reinforcement Learning](archive/2025-05/0529.md#R1-Code-Interpreter-Training-LLMs-to-Reason-with-Code-via-Supervised-and-Reinforcement-Learning)
- [Hardware-Efficient Attention for Fast Decoding](archive/2025-05/0529.md#Hardware-Efficient-Attention-for-Fast-Decoding)
- [rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale Verified Dataset](archive/2025-05/0529.md#rStar-Coder-Scaling-Competitive-Code-Reasoning-with-a-Large-Scale-Verified-Dataset)
- [RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for Complex Task Solving](archive/2025-05/0529.md#RepoMaster-Autonomous-Exploration-and-Understanding-of-GitHub-Repositories-for-Complex-Task-Solving)
- [An LLM-as-Judge Metric for Bridging the Gap with Human Evaluation in SE Tasks](archive/2025-05/0529.md#An-LLM-as-Judge-Metric-for-Bridging-the-Gap-with-Human-Evaluation-in-SE-Tasks)
- [Rendering-Aware Reinforcement Learning for Vector Graphics Generation](archive/2025-05/0529.md#Rendering-Aware-Reinforcement-Learning-for-Vector-Graphics-Generation)
- [SpecExtend: A Drop-in Enhancement for Speculative Decoding of Long Sequences](archive/2025-05/0529.md#SpecExtend-A-Drop-in-Enhancement-for-Speculative-Decoding-of-Long-Sequences)
- [AutoReproduce: Automatic AI Experiment Reproduction with Paper Lineage](archive/2025-05/0529.md#AutoReproduce-Automatic-AI-Experiment-Reproduction-with-Paper-Lineage)
- [Large Language Models for IT Automation Tasks: Are We There Yet?](archive/2025-05/0529.md#Large-Language-Models-for-IT-Automation-Tasks-Are-We-There-Yet)
- [HAMburger: Accelerating LLM Inference via Token Smashing](archive/2025-05/0529.md#HAMburger-Accelerating-LLM-Inference-via-Token-Smashing)
- [SWE-rebench: An Automated Pipeline for Task Collection and Decontaminated Evaluation of Software Engineering Agents](archive/2025-05/0529.md#SWE-rebench-An-Automated-Pipeline-for-Task-Collection-and-Decontaminated-Evaluation-of-Software-Engineering-Agents)
- [An Empirical Study on Strong-Weak Model Collaboration for Repo-level Code Generation](archive/2025-05/0529.md#An-Empirical-Study-on-Strong-Weak-Model-Collaboration-for-Repo-level-Code-Generation)
- [Compliance-to-Code: Enhancing Financial Compliance Checking via Code Generation](archive/2025-05/0529.md#Compliance-to-Code-Enhancing-Financial-Compliance-Checking-via-Code-Generation)
- [ReChisel: Effective Automatic Chisel Code Generation by LLM with Reflection](archive/2025-05/0529.md#ReChisel-Effective-Automatic-Chisel-Code-Generation-by-LLM-with-Reflection)

### 0515-0522

- [Learning to Reason via Mixture-of-Thought for Logical Reasoning](archive/2025-05/0522.md#Learning-to-Reason-via-Mixture-of-Thought-for-Logical-Reasoning)
- [Long-Form Information Alignment Evaluation Beyond Atomic Facts](archive/2025-05/0522.md#Long-Form-Information-Alignment-Evaluation-Beyond-Atomic-Facts)
- [Large Language Models as Computable Approximations to Solomonoff Induction](archive/2025-05/0522.md#Large-Language-Models-as-Computable-Approximations-to-Solomonoff-Induction)
- [dKV-Cache: The Cache for Diffusion Language Models](archive/2025-05/0522.md#dKV-Cache-The-Cache-for-Diffusion-Language-Models)
- [Soft Thinking: Unlocking the Reasoning Potential of LLMs in Continuous Concept Space](archive/2025-05/0522.md#Soft-Thinking-Unlocking-the-Reasoning-Potential-of-LLMs-in-Continuous-Concept-Space)
- [Scalable Defense against In-the-wild Jailbreaking Attacks with Safety Context Retrieval](archive/2025-05/0522.md#Scalable-Defense-against-In-the-wild-Jailbreaking-Attacks-with-Safety-Context-Retrieval)
- [HybridProver: Augmenting Theorem Proving with LLM-Driven Proof Synthesis and Refinement](archive/2025-05/0522.md#HybridProver-Augmenting-Theorem-Proving-with-LLM-Driven-Proof-Synthesis-and-Refinement)
- [VocalBench: Benchmarking the Vocal Conversational Abilities for Speech Interaction Models](archive/2025-05/0522.md#VocalBench-Benchmarking-the-Vocal-Conversational-Abilities-for-Speech-Interaction-Models)
- [Advancing LLM Safe Alignment with Safety Representation Ranking](archive/2025-05/0522.md#Advancing-LLM-Safe-Alignment-with-Safety-Representation-Ranking)
- [LyapLock: Bounded Knowledge Preservation in Sequential Large Language Model Editing](archive/2025-05/0522.md#LyapLock-Bounded-Knowledge-Preservation-in-Sequential-Large-Language-Model-Editing)
- [HDLxGraph: Bridging Large Language Models and HDL Repositories via HDL Graph Databases](archive/2025-05/0522.md#HDLxGraph-Bridging-Large-Language-Models-and-HDL-Repositories-via-HDL-Graph-Databases)
- [Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model](archive/2025-05/0522.md#Efficient-and-Direct-Duplex-Modeling-for-Speech-to-Speech-Language-Model)
- [Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data Could Be Secretly Stolen!](archive/2025-05/0522.md#Be-Careful-When-Fine-tuning-On-Open-Source-LLMs-Your-Fine-tuning-Data-Could-Be-Secretly-Stolen)
- [Guidelines for the Quality Assessment of Energy-Aware NAS Benchmarks](archive/2025-05/0522.md#Guidelines-for-the-Quality-Assessment-of-Energy-Aware-NAS-Benchmarks)
- [DS-Bench: A Realistic Benchmark for Data Science Code Generation](archive/2025-05/0522.md#DS-Bench-A-Realistic-Benchmark-for-Data-Science-Code-Generation)
- [Deep Learning for Continuous-time Stochastic Control with Jumps](archive/2025-05/0522.md#Deep-Learning-for-Continuous-time-Stochastic-Control-with-Jumps)
- [UWSAM: Segment Anything Model Guided Underwater Instance Segmentation and A Large-scale Benchmark Dataset](archive/2025-05/0522.md#UWSAM-Segment-Anything-Model-Guided-Underwater-Instance-Segmentation-and-A-Large-scale-Benchmark-Dataset)
- [Visual Perturbation and Adaptive Hard Negative Contrastive Learning for Compositional Reasoning in Vision-Language Models](archive/2025-05/0522.md#Visual-Perturbation-and-Adaptive-Hard-Negative-Contrastive-Learning-for-Compositional-Reasoning-in-Vision-Language-Models)
- [Bridging the Domain Gap in Equation Distillation with Reinforcement Feedback](archive/2025-05/0522.md#Bridging-the-Domain-Gap-in-Equation-Distillation-with-Reinforcement-Feedback)
- [Moonbeam: A MIDI Foundation Model Using Both Absolute and Relative Music Attributes](archive/2025-05/0522.md#Moonbeam-A-MIDI-Foundation-Model-Using-Both-Absolute-and-Relative-Music-Attributes)
