# Awesome-LLM4Code



## 2025-05 

### 0522-0529

- [Mitigating Overthinking in Large Reasoning Models via Manifold Steering](archive/2025-05/0529.md#Mitigating-Overthinking-in-Large-Reasoning-Models-via-Manifold-Steering)
- [Text2Grad: Reinforcement Learning from Natural Language Feedback](archive/2025-05/0529.md#Text2Grad-Reinforcement-Learning-from-Natural-Language-Feedback)
- [MRT at SemEval-2025 Task 8: Maximizing Recovery from Tables with Multiple Steps](archive/2025-05/0529.md#MRT-at-SemEval-2025-Task-8-Maximizing-Recovery-from-Tables-with-Multiple-Steps)
- [Speculative Decoding Meets Quantization: Compatibility Evaluation and Hierarchical Framework Design](archive/2025-05/0529.md#Speculative-Decoding-Meets-Quantization-Compatibility-Evaluation-and-Hierarchical-Framework-Design)
- [RAD: Redundancy-Aware Distillation for Hybrid Models via Self-Speculative Decoding](archive/2025-05/0529.md#RAD-Redundancy-Aware-Distillation-for-Hybrid-Models-via-Self-Speculative-Decoding)
- [From Coders to Critics: Empowering Students through Peer Assessment in the Age of AI Copilots](archive/2025-05/0529.md#From-Coders-to-Critics-Empowering-Students-through-Peer-Assessment-in-the-Age-of-AI-Copilots)
- [R1-Code-Interpreter: Training LLMs to Reason with Code via Supervised and Reinforcement Learning](archive/2025-05/0529.md#R1-Code-Interpreter-Training-LLMs-to-Reason-with-Code-via-Supervised-and-Reinforcement-Learning)
- [Hardware-Efficient Attention for Fast Decoding](archive/2025-05/0529.md#Hardware-Efficient-Attention-for-Fast-Decoding)
- [rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale Verified Dataset](archive/2025-05/0529.md#rStar-Coder-Scaling-Competitive-Code-Reasoning-with-a-Large-Scale-Verified-Dataset)
- [RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for Complex Task Solving](archive/2025-05/0529.md#RepoMaster-Autonomous-Exploration-and-Understanding-of-GitHub-Repositories-for-Complex-Task-Solving)
- [An LLM-as-Judge Metric for Bridging the Gap with Human Evaluation in SE Tasks](archive/2025-05/0529.md#An-LLM-as-Judge-Metric-for-Bridging-the-Gap-with-Human-Evaluation-in-SE-Tasks)
- [Rendering-Aware Reinforcement Learning for Vector Graphics Generation](archive/2025-05/0529.md#Rendering-Aware-Reinforcement-Learning-for-Vector-Graphics-Generation)
- [SpecExtend: A Drop-in Enhancement for Speculative Decoding of Long Sequences](archive/2025-05/0529.md#SpecExtend-A-Drop-in-Enhancement-for-Speculative-Decoding-of-Long-Sequences)
- [AutoReproduce: Automatic AI Experiment Reproduction with Paper Lineage](archive/2025-05/0529.md#AutoReproduce-Automatic-AI-Experiment-Reproduction-with-Paper-Lineage)
- [Large Language Models for IT Automation Tasks: Are We There Yet?](archive/2025-05/0529.md#Large-Language-Models-for-IT-Automation-Tasks-Are-We-There-Yet)
- [HAMburger: Accelerating LLM Inference via Token Smashing](archive/2025-05/0529.md#HAMburger-Accelerating-LLM-Inference-via-Token-Smashing)
- [SWE-rebench: An Automated Pipeline for Task Collection and Decontaminated Evaluation of Software Engineering Agents](archive/2025-05/0529.md#SWE-rebench-An-Automated-Pipeline-for-Task-Collection-and-Decontaminated-Evaluation-of-Software-Engineering-Agents)
- [An Empirical Study on Strong-Weak Model Collaboration for Repo-level Code Generation](archive/2025-05/0529.md#An-Empirical-Study-on-Strong-Weak-Model-Collaboration-for-Repo-level-Code-Generation)
- [Compliance-to-Code: Enhancing Financial Compliance Checking via Code Generation](archive/2025-05/0529.md#Compliance-to-Code-Enhancing-Financial-Compliance-Checking-via-Code-Generation)
- [ReChisel: Effective Automatic Chisel Code Generation by LLM with Reflection](archive/2025-05/0529.md#ReChisel-Effective-Automatic-Chisel-Code-Generation-by-LLM-with-Reflection)

### 0515-0522

- [Learning to Reason via Mixture-of-Thought for Logical Reasoning](archive/2025-05/0522.md#Learning-to-Reason-via-Mixture-of-Thought-for-Logical-Reasoning)
- [Long-Form Information Alignment Evaluation Beyond Atomic Facts](archive/2025-05/0522.md#Long-Form-Information-Alignment-Evaluation-Beyond-Atomic-Facts)
- [Large Language Models as Computable Approximations to Solomonoff Induction](archive/2025-05/0522.md#Large-Language-Models-as-Computable-Approximations-to-Solomonoff-Induction)
- [dKV-Cache: The Cache for Diffusion Language Models](archive/2025-05/0522.md#dKV-Cache-The-Cache-for-Diffusion-Language-Models)
- [Soft Thinking: Unlocking the Reasoning Potential of LLMs in Continuous Concept Space](archive/2025-05/0522.md#Soft-Thinking-Unlocking-the-Reasoning-Potential-of-LLMs-in-Continuous-Concept-Space)
- [Scalable Defense against In-the-wild Jailbreaking Attacks with Safety Context Retrieval](archive/2025-05/0522.md#Scalable-Defense-against-In-the-wild-Jailbreaking-Attacks-with-Safety-Context-Retrieval)
- [HybridProver: Augmenting Theorem Proving with LLM-Driven Proof Synthesis and Refinement](archive/2025-05/0522.md#HybridProver-Augmenting-Theorem-Proving-with-LLM-Driven-Proof-Synthesis-and-Refinement)
- [VocalBench: Benchmarking the Vocal Conversational Abilities for Speech Interaction Models](archive/2025-05/0522.md#VocalBench-Benchmarking-the-Vocal-Conversational-Abilities-for-Speech-Interaction-Models)
- [Advancing LLM Safe Alignment with Safety Representation Ranking](archive/2025-05/0522.md#Advancing-LLM-Safe-Alignment-with-Safety-Representation-Ranking)
- [LyapLock: Bounded Knowledge Preservation in Sequential Large Language Model Editing](archive/2025-05/0522.md#LyapLock-Bounded-Knowledge-Preservation-in-Sequential-Large-Language-Model-Editing)
- [HDLxGraph: Bridging Large Language Models and HDL Repositories via HDL Graph Databases](archive/2025-05/0522.md#HDLxGraph-Bridging-Large-Language-Models-and-HDL-Repositories-via-HDL-Graph-Databases)
- [Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model](archive/2025-05/0522.md#Efficient-and-Direct-Duplex-Modeling-for-Speech-to-Speech-Language-Model)
- [Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data Could Be Secretly Stolen!](archive/2025-05/0522.md#Be-Careful-When-Fine-tuning-On-Open-Source-LLMs-Your-Fine-tuning-Data-Could-Be-Secretly-Stolen)
- [Guidelines for the Quality Assessment of Energy-Aware NAS Benchmarks](archive/2025-05/0522.md#Guidelines-for-the-Quality-Assessment-of-Energy-Aware-NAS-Benchmarks)
- [DS-Bench: A Realistic Benchmark for Data Science Code Generation](archive/2025-05/0522.md#DS-Bench-A-Realistic-Benchmark-for-Data-Science-Code-Generation)
- [Deep Learning for Continuous-time Stochastic Control with Jumps](archive/2025-05/0522.md#Deep-Learning-for-Continuous-time-Stochastic-Control-with-Jumps)
- [UWSAM: Segment Anything Model Guided Underwater Instance Segmentation and A Large-scale Benchmark Dataset](archive/2025-05/0522.md#UWSAM-Segment-Anything-Model-Guided-Underwater-Instance-Segmentation-and-A-Large-scale-Benchmark-Dataset)
- [Visual Perturbation and Adaptive Hard Negative Contrastive Learning for Compositional Reasoning in Vision-Language Models](archive/2025-05/0522.md#Visual-Perturbation-and-Adaptive-Hard-Negative-Contrastive-Learning-for-Compositional-Reasoning-in-Vision-Language-Models)
- [Bridging the Domain Gap in Equation Distillation with Reinforcement Feedback](archive/2025-05/0522.md#Bridging-the-Domain-Gap-in-Equation-Distillation-with-Reinforcement-Feedback)
- [Moonbeam: A MIDI Foundation Model Using Both Absolute and Relative Music Attributes](archive/2025-05/0522.md#Moonbeam-A-MIDI-Foundation-Model-Using-Both-Absolute-and-Relative-Music-Attributes)
